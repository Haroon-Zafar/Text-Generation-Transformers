{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for h11: [Errno 2] No such file or directory: 'y:\\\\python\\\\lib\\\\site-packages\\\\h11-0.14.0.dist-info\\\\METADATA'\n",
      "    WARNING: No metadata found in y:\\python\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Script folder of your python.exe >> cmd >> pip install -q gradio\n",
    "# \n",
    "%pip install --quiet gradio     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "y:\\python\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initially we have to initialize our model so we use GPT2Tokenizer which tokenizes our input data\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.04M/1.04M [00:04<00:00, 240kB/s] \n",
      "Downloading: 100%|██████████| 456k/456k [00:02<00:00, 225kB/s]  \n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 335kB/s]\n",
      "Downloading: 100%|██████████| 498M/498M [04:58<00:00, 1.67MB/s]  \n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Note : We can also change gpt2-xl for a much more powerful model! \n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# eos_token_id means End-Of-Sequence token id\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69713e280fccb9aa802931bf1b98f79efcfe938b3ab1e86cc85b2e647522a81d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
